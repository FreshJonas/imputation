{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installed with pip\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Included in python 3.10.0\n",
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_pairs = []\n",
    "data_path_pairs.append(('iris' , '../data/iris.csv'))\n",
    "data_path_pairs.append(('wine' , '../data/wine.csv'))\n",
    "data_path_pairs.append(('winequality-red' , '../data/winequality-red.csv'))\n",
    "data_path_pairs.append(('winequality-white' , '../data/winequality-white.csv'))\n",
    "data_path_pairs.append(('abalone' , '../data/abalone.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer_pairs = []\n",
    "imputer_pairs.append(('mean' , SimpleImputer(strategy='mean')))\n",
    "imputer_pairs.append(('median' , SimpleImputer(strategy='median')))\n",
    "imputer_pairs.append(('most_frequent' , SimpleImputer(strategy='most_frequent')))\n",
    "imputer_pairs.append(('knn' , KNNImputer()))\n",
    "imputer_pairs.append(('iterative' , IterativeImputer(random_state = 42, max_iter = 250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentages = [0.10, 0.15, 0.20, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValueListFromIndexListArray(array, indexes):\n",
    "    values = []\n",
    "    for row, col in indexes:\n",
    "        values.append(array[row, col])\n",
    "    return values\n",
    "\n",
    "def GetResultDictionaryForImputation(imputed_array, ix, true_values):\n",
    "    results_per_imputer = {}\n",
    "\n",
    "    # Get Result values\n",
    "    imputed_values = getValueListFromIndexListArray(imputed_array, ix)\n",
    "\n",
    "    # Append MAE and RMSE\n",
    "    results_per_imputer['mae'] = (mean_absolute_error(true_values, imputed_values))\n",
    "    results_per_imputer['rmse'] = (math.sqrt(mean_squared_error(true_values, imputed_values)))\n",
    "\n",
    "    return results_per_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "results = {}\n",
    "\n",
    "# Iterate data sets\n",
    "for data_path_pair in data_path_pairs:\n",
    "    results_per_dataset = {}\n",
    "    \n",
    "    data_name = data_path_pair[0]\n",
    "    data_path = data_path_pair[1]\n",
    "\n",
    "    # Load Data\n",
    "    data_true = pd.read_csv(data_path).to_numpy()\n",
    "    data_scaled = scaler.fit_transform(data_true)\n",
    "\n",
    "    ## Get all Indexes\n",
    "    ix = [(row, col) for row in range(data_scaled.shape[0]) for col in range(data_scaled.shape[1])]\n",
    "\n",
    "    # Get true values\n",
    "    true_values = getValueListFromIndexListArray(data_scaled, ix)\n",
    "\n",
    "    for missing_percentage in missing_percentages:\n",
    "        results_per_percentage = {}\n",
    "\n",
    "        # Create Dropped Data\n",
    "        data_dropped = data_scaled.copy()\n",
    "\n",
    "        ## Inserting random nan values\n",
    "        random.seed(42)\n",
    "        for row, col in random.sample(ix, int(round(missing_percentage*len(ix))), ):\n",
    "            data_dropped[row, col] = np.nan\n",
    "        \n",
    "        # # Save dropped df locally\n",
    "        # pd.DataFrame(data_dropped).to_csv(f'../data/svd/{data_name}_{missing_percentage}_dropped.csv', index=None)\n",
    "        \n",
    "        # Iterate through Imputers\n",
    "        for imputer_pair in imputer_pairs:\n",
    "\n",
    "            # Impute\n",
    "            imputer_name = imputer_pair[0]\n",
    "            imputer = imputer_pair[1]\n",
    "            imputed_array = imputer.fit_transform(data_dropped)\n",
    "\n",
    "            results_per_percentage[imputer_name] = GetResultDictionaryForImputation(imputed_array, ix, true_values)\n",
    "        \n",
    "        # Add SVD Results\n",
    "        svd_imputed_array = pd.read_csv(f'../data/svd/{data_name}_{missing_percentage}_imputed.csv', index_col=0).to_numpy()\n",
    "        results_per_percentage['svd'] = GetResultDictionaryForImputation(svd_imputed_array, ix, true_values)\n",
    "        \n",
    "        results_per_dataset[missing_percentage] = (results_per_percentage)\n",
    "    \n",
    "    results[data_name] = results_per_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: {'mean': {'mae': 0.021708126417943313, 'rmse': 0.0844547082111173},\n",
       "  'median': {'mae': 0.02362445072190835, 'rmse': 0.09319324465803813},\n",
       "  'most_frequent': {'mae': 0.02461785938480854, 'rmse': 0.108065503281979},\n",
       "  'knn': {'mae': 0.007312460765850597, 'rmse': 0.03198552443223404},\n",
       "  'iterative': {'mae': 0.007959949887017906, 'rmse': 0.031932083795739044},\n",
       "  'svd': {'mae': 0.01305158391548032, 'rmse': 0.06251261822500481}},\n",
       " 0.15: {'mean': {'mae': 0.0312846372663869, 'rmse': 0.09874734783902572},\n",
       "  'median': {'mae': 0.033265458254865043, 'rmse': 0.10723451201918283},\n",
       "  'most_frequent': {'mae': 0.03962688323917137, 'rmse': 0.13501179708135153},\n",
       "  'knn': {'mae': 0.01368047708725675, 'rmse': 0.04682911081741574},\n",
       "  'iterative': {'mae': 0.012863322683347323, 'rmse': 0.042501139635590136},\n",
       "  'svd': {'mae': 0.023182909911519767, 'rmse': 0.09114978788372181}},\n",
       " 0.2: {'mean': {'mae': 0.04188951663527935, 'rmse': 0.11488468840147235},\n",
       "  'median': {'mae': 0.04418628374136849, 'rmse': 0.12492187894264799},\n",
       "  'most_frequent': {'mae': 0.056949152542372886, 'rmse': 0.16587828311837216},\n",
       "  'knn': {'mae': 0.01894577840552417, 'rmse': 0.05686699013931719},\n",
       "  'iterative': {'mae': 0.016722006636114735, 'rmse': 0.04948438632912931},\n",
       "  'svd': {'mae': 0.034329066383492306, 'rmse': 0.11735354932323849}},\n",
       " 0.25: {'mean': {'mae': 0.05226142485074046, 'rmse': 0.12758986761308355},\n",
       "  'median': {'mae': 0.05315756434400503, 'rmse': 0.13510202775676272},\n",
       "  'most_frequent': {'mae': 0.0731002824858757, 'rmse': 0.1912323070542297},\n",
       "  'knn': {'mae': 0.025454017576898934, 'rmse': 0.07110451830467257},\n",
       "  'iterative': {'mae': 0.02188327120003725, 'rmse': 0.05830789745377581},\n",
       "  'svd': {'mae': 0.04834092067868542, 'rmse': 0.14195607475060873}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['iris']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imputation_env",
   "language": "python",
   "name": "imput_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 | packaged by conda-forge | (default, Nov 10 2021, 13:20:59) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e3e01d6e3c159f62477afa336556ba26f892b536a40fbf10efa34ee5eed1de3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
